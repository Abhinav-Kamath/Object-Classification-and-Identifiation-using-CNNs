{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# VR Assignment 3 - Part B","metadata":{}},{"cell_type":"markdown","source":"## Initial Imports","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F \nimport torchvision.utils as utils\nimport cv2 \nimport matplotlib.pyplot as plt\nimport numpy as np \nfrom PIL import Image, ImageOps\nimport argparse\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-30T16:17:10.537693Z","iopub.execute_input":"2022-03-30T16:17:10.538500Z","iopub.status.idle":"2022-03-30T16:17:12.329661Z","shell.execute_reply.started":"2022-03-30T16:17:10.538241Z","shell.execute_reply":"2022-03-30T16:17:12.328675Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Data Reads","metadata":{}},{"cell_type":"code","source":"TrainDirectory = \"../input/spider-dataset/train\"\nTestDirectory = \"../input/spider-dataset/test\"\nCategories = os.listdir(TrainDirectory)\nTestCategories = os.listdir(TestDirectory)\n\n\n# TrainDirectory = \"../input/bikesvshorses/Assignment2_BikeHorses/\"\n# Categories = os.listdir(TrainDirectory)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:17:12.331497Z","iopub.execute_input":"2022-03-30T16:17:12.331735Z","iopub.status.idle":"2022-03-30T16:17:12.341648Z","shell.execute_reply.started":"2022-03-30T16:17:12.331709Z","shell.execute_reply":"2022-03-30T16:17:12.340526Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Initial Data Transform","metadata":{}},{"cell_type":"code","source":"data_transforms = transforms.Compose([\n        transforms.Resize((224,224)),      \n        transforms.ToTensor(),             \n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  \n    ])","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:17:12.343924Z","iopub.execute_input":"2022-03-30T16:17:12.344821Z","iopub.status.idle":"2022-03-30T16:17:12.351136Z","shell.execute_reply.started":"2022-03-30T16:17:12.344783Z","shell.execute_reply":"2022-03-30T16:17:12.350124Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Creating a list of transformed train and test images","metadata":{}},{"cell_type":"code","source":"Data = []\nlabels = []\n\nfor category in Categories:\n    fileLabel = Categories.index(category)\n    for file in os.listdir(os.path.join(TrainDirectory, category)):\n        img =  Image.open(os.path.join(TrainDirectory, category, file))\n        labels.append(fileLabel)\n        transformed_img = data_transforms(img)\n        Data.append(torch.unsqueeze(transformed_img, 0))    ","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:17:12.353452Z","iopub.execute_input":"2022-03-30T16:17:12.353713Z","iopub.status.idle":"2022-03-30T16:17:21.403580Z","shell.execute_reply.started":"2022-03-30T16:17:12.353684Z","shell.execute_reply":"2022-03-30T16:17:21.402664Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"test = []\ntestLabels = []\n\nfor category in TestCategories:\n    fileLabel = TestCategories.index(category)\n    for file in os.listdir(os.path.join(TestDirectory, category)):\n        img =  Image.open(os.path.join(TestDirectory, category, file))\n        testLabels.append(fileLabel)\n        transformed_img = data_transforms(img)\n        test.append(torch.unsqueeze(transformed_img, 0))    \n","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:17:21.405195Z","iopub.execute_input":"2022-03-30T16:17:21.405485Z","iopub.status.idle":"2022-03-30T16:17:21.676168Z","shell.execute_reply.started":"2022-03-30T16:17:21.405448Z","shell.execute_reply":"2022-03-30T16:17:21.675421Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Initialising pretrained alexnet","metadata":{}},{"cell_type":"code","source":"alexnet = models.alexnet(pretrained = True)\nalexnet.eval()","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:17:21.677544Z","iopub.execute_input":"2022-03-30T16:17:21.678325Z","iopub.status.idle":"2022-03-30T16:17:22.536730Z","shell.execute_reply.started":"2022-03-30T16:17:21.678286Z","shell.execute_reply":"2022-03-30T16:17:22.535828Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Feature extraction using pretrained Alexnet","metadata":{}},{"cell_type":"code","source":"features = []\ni = 0\nfor img in Data:\n    with torch.no_grad():\n        feature = alexnet(img).detach().numpy()\n    features.append(feature)\n    if i%100 == 0:\n        print(str(i) + \" training images appended\")\n    i+=1\nprint(\"All Training Images Appended!\")","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:17:22.537914Z","iopub.execute_input":"2022-03-30T16:17:22.538173Z","iopub.status.idle":"2022-03-30T16:18:27.593297Z","shell.execute_reply.started":"2022-03-30T16:17:22.538143Z","shell.execute_reply":"2022-03-30T16:18:27.592330Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"i = 0\ntestFeatures = []\nfor img in test:\n    with torch.no_grad():\n        feature = alexnet(img).detach().numpy()\n    testFeatures.append(feature)    \n    if i%10 == 0:\n        print(str(i) + \" testing images appended\")\n    i+=1\nprint(\"All Testing Images Appended!\")","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:18:27.594570Z","iopub.execute_input":"2022-03-30T16:18:27.594910Z","iopub.status.idle":"2022-03-30T16:18:29.830639Z","shell.execute_reply.started":"2022-03-30T16:18:27.594877Z","shell.execute_reply":"2022-03-30T16:18:29.829717Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Converting 3d feature array to 2d for training","metadata":{}},{"cell_type":"code","source":"features[0].shape\nfeatures = np.array(features).reshape(len(features), features[0].shape[0]*features[0].shape[1])","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:18:29.832122Z","iopub.execute_input":"2022-03-30T16:18:29.832367Z","iopub.status.idle":"2022-03-30T16:18:29.845135Z","shell.execute_reply.started":"2022-03-30T16:18:29.832338Z","shell.execute_reply":"2022-03-30T16:18:29.844190Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"testFeatures = np.array(testFeatures).reshape(len(testFeatures), testFeatures[0].shape[0]*testFeatures[0].shape[1])","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:18:29.849490Z","iopub.execute_input":"2022-03-30T16:18:29.849864Z","iopub.status.idle":"2022-03-30T16:18:29.855930Z","shell.execute_reply.started":"2022-03-30T16:18:29.849814Z","shell.execute_reply":"2022-03-30T16:18:29.855052Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## TrainTestSplit of features list (Run for BikeVsHorse)","metadata":{}},{"cell_type":"code","source":"# features, testFeatures, labels, testLabels = train_test_split(features, labels, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:18:29.857557Z","iopub.execute_input":"2022-03-30T16:18:29.857865Z","iopub.status.idle":"2022-03-30T16:18:29.866858Z","shell.execute_reply.started":"2022-03-30T16:18:29.857824Z","shell.execute_reply":"2022-03-30T16:18:29.865867Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Training different classification models using features extracted from pre-trained Alexnet","metadata":{}},{"cell_type":"markdown","source":"### LogisticRegression Model","metadata":{}},{"cell_type":"code","source":"lrmodel = LogisticRegression(solver = 'saga', max_iter = 1000)\nlrmodel.fit(features, labels)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:18:29.868133Z","iopub.execute_input":"2022-03-30T16:18:29.868461Z","iopub.status.idle":"2022-03-30T16:22:32.230297Z","shell.execute_reply.started":"2022-03-30T16:18:29.868433Z","shell.execute_reply":"2022-03-30T16:22:32.229227Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"y_pred = lrmodel.predict(testFeatures)\nacc = accuracy_score(y_pred, testLabels)\nprint(acc)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:22:32.231799Z","iopub.execute_input":"2022-03-30T16:22:32.232556Z","iopub.status.idle":"2022-03-30T16:22:32.243454Z","shell.execute_reply.started":"2022-03-30T16:22:32.232510Z","shell.execute_reply":"2022-03-30T16:22:32.241795Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"### SVM model","metadata":{}},{"cell_type":"code","source":"clf = LinearSVC(max_iter = 5000)\nclf.fit(features,np.array(labels))","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:22:32.245473Z","iopub.execute_input":"2022-03-30T16:22:32.246344Z","iopub.status.idle":"2022-03-30T16:22:56.127794Z","shell.execute_reply.started":"2022-03-30T16:22:32.246282Z","shell.execute_reply":"2022-03-30T16:22:56.126834Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"y_pred = clf.predict(testFeatures)\nacc = accuracy_score(y_pred, testLabels)\nprint(acc)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:22:56.128979Z","iopub.execute_input":"2022-03-30T16:22:56.129241Z","iopub.status.idle":"2022-03-30T16:22:56.143575Z","shell.execute_reply.started":"2022-03-30T16:22:56.129212Z","shell.execute_reply":"2022-03-30T16:22:56.142152Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"### GNB model","metadata":{}},{"cell_type":"code","source":"gnb = GaussianNB()\ngnb.fit(features, labels)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:22:56.145802Z","iopub.execute_input":"2022-03-30T16:22:56.146213Z","iopub.status.idle":"2022-03-30T16:22:56.181679Z","shell.execute_reply.started":"2022-03-30T16:22:56.146164Z","shell.execute_reply":"2022-03-30T16:22:56.180682Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"y_pred = gnb.predict(testFeatures)\nacc = accuracy_score(y_pred, testLabels)\nprint(acc)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:22:56.183492Z","iopub.execute_input":"2022-03-30T16:22:56.184075Z","iopub.status.idle":"2022-03-30T16:22:56.201719Z","shell.execute_reply.started":"2022-03-30T16:22:56.184012Z","shell.execute_reply":"2022-03-30T16:22:56.200750Z"},"trusted":true},"execution_count":17,"outputs":[]}]}